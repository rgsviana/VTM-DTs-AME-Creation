# -*- coding: utf-8 -*-
"""Treino_DT_AME.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MunnQIoGpaZHM5SD6BwFvxyGiswhUm5T

## TAMANHO DA CU PARA CRIAR A SUA ÁRVORE DE DECISÃO
"""

cu_eixo_x = 128
cu_eixo_y = 128

"""## HIPERPARAMETROS PARA ESTA CU"""

hiper_criterion = 'gini'
hiper_min_samples_split = 200
hiper_min_samples_leaf = 40
hiper_max_features = 43
hiper_max_depth = 9
hiper_max_leaf_nodes = 9

"""## PREPARAÇÃO DOS ARQUIVOS"""

!pip install scikit-learn

from google.colab import drive
drive.mount('/content/drive')

"""## DATASET TESTE"""

!ls 'drive/My Drive/Mestrado/Dissertação/Treinamento DTs AME/VTM 16.2 - AME - Dataset Teste'

import glob
lista = glob.glob ('drive/My Drive/Mestrado/Dissertação/Treinamento DTs AME/VTM 16.2 - AME - Dataset Teste/*.csv')

labels = ["qp", "depth", "qt_depht", "mt_depth", "video_width", "video_heigh", "cu_pos_x", "cu_pos_y", "cu_width", "cu_height", "bcw_index", "imv", "mv_uni_l0_hor_x", "mv_uni_l0_ver_y", "mv_uni_l1_hor_x", "mv_uni_l1_ver_y", "cost_mv_uni_l0", "cost_mv_uni_l1", "bits_mv_uni_l0", "bits_mv_uni_l1", "mv_bi_l0_hor_x", "mv_bi_l0_ver_y", "mv_bi_l1_hor_x", "mv_bi_l1_ver_y", "cost_bi", "bits_mv_bi", "smvd", "inter_dir_normal", "atual_QP", "affine_pai", "custo_pai", "aff_viz_esq", "aff_viz_esq_1", "custo_viz_esq", "aff_viz_acima", "aff_viz_acima_1", "custo_viz_aci", "cu_atual_affine", "aff_inter_dir", "sum", "media", "vari", "gradH", "gradV", "razao_grad", "grad_razao_pixels", "desvioPadrao", "executaAffine"]

blocksize = [cu_eixo_x, cu_eixo_y]

import pandas as pd
import gc

dataframe_teste = pd.DataFrame()
for csv in lista:
  print (csv)
  d = pd.read_csv (csv, sep=";", nrows=100000)
  #d.drop(columns=["inter_dir_normal"])
  d = d[d["cu_width"] == blocksize[0]]
  d = d[d["cu_height"] == blocksize[1]]

  n_linhas = len(d)
  if n_linhas > 1000:
    n_linhas_remover = n_linhas - 1000
    linhas_remover = d.sample(n=n_linhas_remover).index
    d = d.drop(linhas_remover)

  dataframe_teste = pd.concat([dataframe_teste, d], axis=0)
  del d
  gc.collect()

dataframe_teste

"""## DATASET TREINO"""

!ls 'drive/My Drive/Mestrado/Dissertação/Treinamento DTs AME/VTM 16.2 - AME - Dataset Treino'

import glob
lista = glob.glob ('drive/My Drive/Mestrado/Dissertação/Treinamento DTs AME/VTM 16.2 - AME - Dataset Treino/*.csv')

labels = ["qp", "depth", "qt_depht", "mt_depth", "video_width", "video_heigh", "cu_pos_x", "cu_pos_y", "cu_width", "cu_height", "bcw_index", "imv", "mv_uni_l0_hor_x", "mv_uni_l0_ver_y", "mv_uni_l1_hor_x", "mv_uni_l1_ver_y", "cost_mv_uni_l0", "cost_mv_uni_l1", "bits_mv_uni_l0", "bits_mv_uni_l1", "mv_bi_l0_hor_x", "mv_bi_l0_ver_y", "mv_bi_l1_hor_x", "mv_bi_l1_ver_y", "cost_bi", "bits_mv_bi", "smvd", "inter_dir_normal", "atual_QP", "affine_pai", "custo_pai", "aff_viz_esq", "aff_viz_esq_1", "custo_viz_esq", "aff_viz_acima", "aff_viz_acima_1", "custo_viz_aci", "cu_atual_affine", "aff_inter_dir", "sum", "media", "vari", "gradH", "gradV", "razao_grad", "grad_razao_pixels", "desvioPadrao", "executaAffine"]

blocksize = [cu_eixo_x, cu_eixo_y]

import pandas as pd
import gc
dataframe_treino = pd.DataFrame()
for csv in lista:
  print (csv)
  d = pd.read_csv (csv, sep=";", nrows=1000000)
  #d.drop(columns=["inter_dir_normal"])
  d = d[d["cu_width"] == blocksize[0]]
  d = d[d["cu_height"] == blocksize[1]]

  n_linhas = len(d)
  if n_linhas > 10000:
    n_linhas_remover = n_linhas - 10000
    linhas_remover = d.sample(n=n_linhas_remover).index
    d = d.drop(linhas_remover)

  dataframe_treino = pd.concat([dataframe_treino, d], axis=0)
  del d
  gc.collect()

dataframe_treino

"""## PREPARAÇÃO PARA EXECUTAR AS ÁRVORES DE DECISÃO"""

from os import listdir
from os import chdir
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import accuracy_score
from collections import Counter
from imblearn.under_sampling import RandomUnderSampler
#from sklearn import preprocessing
#from sklearn import utils

!pip install m2cgen
import m2cgen as m2c
import gc

import seaborn as sns

"""## TESTE DA ÁRVORE DE DECISÃO"""

def apply_Decision_Tree(_X_train, _y_train, _nome_arq, _save_path):

	model_decison_tree_class.fit(_X_train,_y_train)

	code_DT_em_C = m2c.export_to_c(model_decison_tree_class)

	file = open(_save_path+'DT_AME_'+_nome_arq+'.cpp', 'w')
	file.write(code_DT_em_C)
	file.close()

save_path = "drive/My Drive/Mestrado/Dissertação/Treinamento DTs AME/"

features = [
    'qp',
    'depth',
    'qt_depht',
    'mt_depth',
    #'video_width',
    #'video_heigh',
    'cu_pos_x',
    'cu_pos_y',
    'cu_width',
    'cu_height',
    #'bcw_index',
    #'imv',
    'mv_uni_l0_hor_x',
    'mv_uni_l0_ver_y',
    'mv_uni_l1_hor_x',
    'mv_uni_l1_ver_y',
    'cost_mv_uni_l0',
    'cost_mv_uni_l1',
    'bits_mv_uni_l0',
    'bits_mv_uni_l1',
    'mv_bi_l0_hor_x',
    'mv_bi_l0_ver_y',
    'mv_bi_l1_hor_x',
    'mv_bi_l1_ver_y',
    'cost_bi',
    'bits_mv_bi',
    #'smvd',
    #'inter_dir_normal',
    'atual_QP',
    'affine_pai',
    'custo_pai',
    'aff_viz_esq',
    'aff_viz_esq_1',
    'custo_viz_esq',
    'aff_viz_acima',
    'aff_viz_acima_1',
    'custo_viz_aci',
    #'cu_atual_affine',
    #'aff_inter_dir',
    'sum',
    'media',
    'vari',
    'gradH',
    'gradV',
    'razao_grad',
    'grad_razao_pixels',
    'desvioPadrao'
    ]

#y_treino = dataframe_treino.executaAffine
y_treino = dataframe_treino.executaAffine.astype(int)
X_treino = dataframe_treino[features]

#y_teste = dataframe_teste.executaAffine
y_teste = dataframe_teste.executaAffine.astype(int)
X_teste = dataframe_teste[features]

undersample = RandomUnderSampler(sampling_strategy = 'majority', random_state = 12)

X_under, y_under = undersample.fit_resample(X_treino, y_treino)
X_t, y_t = undersample.fit_resample(X_teste, y_teste)

model_decison_tree_class = DecisionTreeClassifier(criterion = hiper_criterion, min_samples_split = hiper_min_samples_split, min_samples_leaf = hiper_min_samples_leaf, max_features = hiper_max_features, max_depth = hiper_max_depth, max_leaf_nodes = hiper_max_leaf_nodes)
model_decison_tree_class.fit(X_under, y_under)
val_predictions = model_decison_tree_class.predict(X_t)
print("Accuracy:",metrics.accuracy_score(y_t, val_predictions))
print("Precision:",metrics.precision_score(y_t, val_predictions))
print("Recall:",metrics.recall_score(y_t, val_predictions))
print("F1:",metrics.f1_score(y_t, val_predictions))

feat_importances = pd.DataFrame(model_decison_tree_class.feature_importances_, index = X_treino.columns, columns = ["Importance"])
feat_importances.sort_values(by = 'Importance', ascending = False, inplace = True)
feat_importances.plot(kind='bar', figsize=(12,6))

"""## TREINAMENTO DA ÁRVORE DE DECISÃO"""

def apply_Decision_Tree(_X_train, _y_train, _nome_arq, _save_path):

	model_decison_tree_class.fit(_X_train,_y_train)

	code_DT_em_C = m2c.export_to_c(model_decison_tree_class)

	file = open(_save_path+'DT_AME_'+_nome_arq+'.cpp', 'w')
	file.write(code_DT_em_C)
	file.close()

save_path = "drive/My Drive/Mestrado/Dissertação/Treinamento DTs AME/"

features = [
    'qp',
    'depth',
    'qt_depht',
    'mt_depth',
    #'video_width',
    #'video_heigh',
    'cu_pos_x',
    'cu_pos_y',
    'cu_width',
    'cu_height',
    #'bcw_index',
    #'imv',
    'mv_uni_l0_hor_x',
    'mv_uni_l0_ver_y',
    'mv_uni_l1_hor_x',
    'mv_uni_l1_ver_y',
    'cost_mv_uni_l0',
    'cost_mv_uni_l1',
    'bits_mv_uni_l0',
    'bits_mv_uni_l1',
    'mv_bi_l0_hor_x',
    'mv_bi_l0_ver_y',
    'mv_bi_l1_hor_x',
    'mv_bi_l1_ver_y',
    'cost_bi',
    'bits_mv_bi',
    #'smvd',
    #'inter_dir_normal',
    'atual_QP',
    'affine_pai',
    'custo_pai',
    'aff_viz_esq',
    'aff_viz_esq_1',
    'custo_viz_esq',
    'aff_viz_acima',
    'aff_viz_acima_1',
    'custo_viz_aci',
    #'cu_atual_affine',
    #'aff_inter_dir',
    'sum',
    'media',
    'vari',
    'gradH',
    'gradV',
    'razao_grad',
    'grad_razao_pixels',
    'desvioPadrao'
    ]

dataframe_final = pd.concat([dataframe_treino, dataframe_treino], axis=0)

y_final = dataframe_final.executaAffine.astype(int)
#y_final = dataframe_final.executaAffine
X_final = dataframe_final[features]

undersample = RandomUnderSampler(sampling_strategy = 'majority', random_state = 12)

X_under, y_under = undersample.fit_resample(X_final, y_final)

model_decison_tree_class = DecisionTreeClassifier(criterion = hiper_criterion, min_samples_split = hiper_min_samples_split, min_samples_leaf = hiper_min_samples_leaf, max_features = hiper_max_features, max_depth = hiper_max_depth, max_leaf_nodes = hiper_max_leaf_nodes)
model_decison_tree_class.fit(X_under, y_under)

apply_Decision_Tree(X_under, y_under, str(cu_eixo_x)+'x'+str(cu_eixo_y), save_path)